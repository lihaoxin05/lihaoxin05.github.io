<html>
<head>
<style>
    .figure{float:left;width:30%;}
    .figure img{display:block;width:75%}
    .text{float:right;width:70%}
</style>
</head>
<body>
    <div class="figure">
        <img src="/images/personal.jpg">
    </div>
    <div class="text">
        <p><b>Haoxin Li</b> &nbsp;&nbsp;&nbsp; <b>李昊昕</b></p>
        <p>M.Sc. Student</p>
        <p>SUN YAT-SEN UNIVERSITY, China</p>
        <p>Email: lihaoxin05@gmail.com</p>
        <br>
    </div>
</body>
</html>  

## About Me ([CV](/files/lihaoxin_cv.pdf))
I am currently a M.Sc. student at Sun Yat-Sen University, supervised by [Prof. Wei-Shi Zheng](http://www.isee-ai.cn/~zhwshi/). My research interest is computer vision and I am currently working on human action and interaction analysis in videos. 

## Education
- **Sun Yat-Sen University**: Aug., 2018 – June, 2021  
   - M.Sc. in Information and Communication Engineering
- **Sun Yat-Sen University**: Aug., 2014 – June, 2018  
   - B.E. in Electronic Engineering

## Publications
- **Haoxin Li**, Wei-Shi Zheng, Yu Tao, Haifeng Hu, Jian-Huang Lai. Adaptive Interaction Modeling via Graph Operations Search. In IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2020. [[arxiv](http://arxiv.org/abs/2005.02113)][[code](https://github.com/lihaoxin05/graph-operations-search)][[paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adaptive_Interaction_Modeling_via_Graph_Operations_Search_CVPR_2020_paper.pdf)][[supplementary material](http://openaccess.thecvf.com/content_CVPR_2020/supplemental/Li_Adaptive_Interaction_Modeling_CVPR_2020_supplemental.zip)]
    <details>
    <summary>Summary</summary>
    To learn adaptive structures to model interactions in different videos for interaction recognition, we automate the process of structures design by searching for adaptive network structures with differentiable architecture search mechanism, which facilitates adaptive interaction modeling in videos.
    <pre><center><img src="/images/CVPR2020_framework.jpg" width="90%"></center></pre>
    </details>

- **Haoxin Li**, Wei-Shi Zheng, Jianguo Zhang, Haifeng Hu, Jiwen Lu, Jian-Huang Lai. Egocentric Action Recognition by Automatic
Relation Modeling (**TPAMI**), 2022. [[code](https://github.com/lihaoxin05/egocentric-interaction/tree/master/human-human%20interaction)]
    <details>
    <summary>Summary</summary>
    In this work, we consider modeling the relations in a weakly supervised manner, \ie without using annotations or prior knowledge about the interacting persons or objects, for egocentric action recognition. We form a weakly supervised framework by unifying automatic interactor localization and explicit relation modeling for the purpose of automatic relation modeling.
    <pre><center><img src="/images/TPAMI2022_framework.jpg" width="90%"></center></pre>
    </details>

- **Haoxin Li**, Yijun Cai, Wei-Shi Zheng. Deep Dual Relation Modeling for Egocentric Interaction Recognition. In IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2019. [[arxiv](http://arxiv.org/abs/1905.13586)][[code](https://github.com/lihaoxin05/egocentric-interaction/tree/master/human-human%20interaction)][[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Deep_Dual_Relation_Modeling_for_Egocentric_Interaction_Recognition_CVPR_2019_paper.pdf)] [[supplementary material](http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Li_Deep_Dual_Relation_CVPR_2019_supplemental.pdf)]
    <details>
    <summary>Summary</summary>
    To exploit the strong relations between the two interacting persons in egocentric videos for egocentric interaction recognition, we introduce a dual relation modeling framework which learns to model the relations between the camera wearer and the interactor based on the individual action representations of the two persons.
    <pre><center><img src="/images/CVPR2019_framework.jpg" width="90%"></center></pre>
    </details>

- Yijun Cai, **Haoxin Li**, Jian-Fang Hu, Wei-Shi Zheng. Action Knowledge Transfer for Action Prediction with Partial Videos. In 33rd AAAI Conference on Artificial Intelligence (**AAAI**), 2019. [[paper](https://aaai.org/ojs/index.php/AAAI/article/view/4820/4693)]

- Shuosen Guan, **Haoxin Li**, Wei-Shi Zheng. Unsupervised Learning for Optical Flow Estimation Using Pyramid Convolution LSTM. In IEEE International Conference on Multimedia and Expo (**ICME**), 2019. [[paper](https://arxiv.org/pdf/1907.11628.pdf)]

- Jiaming Zhou, Kun-Yu Lin, **Haoxin Li**, Wei-Shi Zheng. Graph-Based High-Order Relation Modeling for Long-Term Action Recognition. In IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2021. [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Graph-Based_High-Order_Relation_Modeling_for_Long-Term_Action_Recognition_CVPR_2021_paper.pdf)]

## Contests
- [ActivityNet Large-Scale Activity Recognition Challenge 2018](http://activity-net.org/challenges/2018/index.html): Trimmed Event Recognition ([Moments in Time Recognition Challenge](http://moments.csail.mit.edu/challenge.html)), **Rank**: 1/12 in Mini Track, 10/29 in Full Track. [[report](http://moments.csail.mit.edu/challenge2018/SYSU_isee.pdf)]

## Awards
- Outstanding Undergraduate Thesis Award, by Sun Yat-sen University, 2018
- Chinese National Scholarship (1/264), by Minister of Education of China, 2015
